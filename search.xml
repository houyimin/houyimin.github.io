<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[supervisor进程管理]]></title>
    <url>%2F2019%2F12%2F10%2Fsupervisor%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Supervisor是个客户端/服务器系统可以在类UNIX操作系统上管理一些进程 Supervisord将进程作为其子进程启动，并且可以配置为在崩溃时自动重新启动它们。它还可以自动配置为自行调用启动进程 如果以root用户身份启动Supervisor，则可以允许普通用户控制此类进程。 Supervisorctl允许用户通过简单的shell或Web UI发出”停止”，”启动”和”重新启动”命令来查看进程状态并管理受supervisord控制的子进程 进程通常需要成组地启动和停止，有时甚至需要按照”优先级顺序”执行。 Supervisor允许您为进程分配优先级，并允许用户通过supervisorctl发出命令，如”全部启动”和”全部重新启动”，这将按照预先分配的优先级顺序启动它们。此外，可以将进程分为”进程组”，并且可以将一组逻辑相关的进程作为一个单元停止和启动。 Supervisor 组件1、supervisord supervisor的服务器端为supervisord ，它负责自行调用启动子程序，响应来自客户端的命令，重新启动崩溃或退出的子进程，记录其子进程stdout和stderr输出。服务进程使用配置文件，通常位于 /etc/supervisord.conf. 这个文件是 “Windows-INI” 类型的配置文件. 保持这个文件在文件系统的安全很重要， 因为它可能包含未加密的用户名和密码。 2、supervisorctl supervisor的客户端命令行部分是supervisorctl. 它提供了类似shell的接口访问 supervisord的功能. 通过 supervisorctl用户可以连接不同的 supervisord进程 (同时), 获取子进程的状态, 停止和启动子进程, 获取supervisord正在运行的子进程列表. 3、Web Server 激活配置文件的[inet_http_server]部分后，可以访问URL（例如http://localhost:9001 ）以通过Web界面查看和控制进程状态 安装1pip install supervisor 配置安装完 supervisor 之后，可以运行echo_supervisord_conf 命令输出默认的配置项，也可以重定向到一个配置文件里1echo_supervisord_conf &gt; /etc/supervisord.conf 1、主要配置项 [supervisord]logfile=/tmp/supervisord.log ; supervisord 主要的日志文件 [include]files = /etc/supervisor/*.ini ; 加载需要管理程序的配置文件 2、需要管理程序的配置文件格式如下，例如需要管理elasticsearch的配置文件，命名为 es1.ini，program中的es1代表程序的唯一标识，不能重复 [program:es1]command = /home/elastic/elasticsearch-7.4.2/bin/elasticsearch ;启动命令autostart = true ; 在 supervisord 启动的时候也自动启动startsecs = 5 ; 启动 5 秒后没有异常退出，就当作已经正常启动了autorestart = true ; 程序异常退出后自动重启startretries = 3 ; 启动失败自动重试次数，默认是 3user = es ;启动用户redirect_stderr = true ; 把 stderr 重定向到 stdout，默认 falsestdout_logfile_maxbytes = 100MB ; stdout 日志文件大小，默认 50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数stdout_logfile = /var/log/es1/es1.log ; stdout日志文件 启动supervisord1supervisord -c /etc/supervisord.conf 查看 supervisord 是否在运行：1ps aux | grep supervisord 注意1、后台进程 supervisord 要求管理的程序是非 daemon 程序，supervisord 会帮你把它转成 daemon 程序，因此如果用 supervisord 来管理进程，进程需要以非daemon的方式启动。 例如：管理nginx 的话，必须在 nginx 的配置文件里添加一行设置 daemon off 让 nginx 以非 daemon 方式启动 2、子进程 有时候用 Supervisor 托管的程序还会有子进程（如 Tornado），如果只杀死主进程，子进程就可能变成孤儿进程。通过这两项配置来确保所有子进程都能正确停止： 12stopasgroup=truekillasgroup=true 使用 supervisorctlsupervisorctl 是 supervisord 的一个命令行客户端工具 输入 supervisorctl 进入交互命令123456$ supervisorctl &gt; status # 查看程序状态&gt; stop es1 # 关闭 es1 程序&gt; start es1 # 启动 es1 程序&gt; restart es1 # 重启 es1 程序 除了进入 supervisorctl 的 shell 界面，也可以直接在 bash 终端运行 12345$ supervisorctl status$ supervisorctl stop es1$ supervisorctl start es1$ supervisorctl restart es1]]></content>
      <categories>
        <category>Python</category>
        <category>supervisor</category>
      </categories>
      <tags>
        <tag>Python,supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件比对sdiff]]></title>
    <url>%2F2019%2F11%2F21%2FLinux%E6%96%87%E4%BB%B6%E6%AF%94%E5%AF%B9sdiff%2F</url>
    <content type="text"><![CDATA[sdiff命令以并排形式显示文件差异。以下是其语法： sdiff [OPTION]... FILE1 FILE2 一、基本用法sdiff file1 file2 文件1和文件2内容一样，如下 $ cat file1 1 2 3 4 5 6 $ cat file2 1 2 3 4 5 6 输出比较结果： $ sdiff file1 file2 1 1 2 2 3 3 4 4 5 5 6 6 这意味着2个文件相同 二、使sdiff忽略大小写假设文件如下： $ cat file1 1A 2 3 4 5 6 $ cat file1 1a 2 3 4 5 6 输出： $ sdiff file1 file2 1A | 1a 2 2 3 3 4 4 5 5 6 6 第二列第一行中的管道（|）表示两个文件在第一行本身是不同的。但是，如果需要，可以强制sdiff忽略大小写，这可以使用-i命令行选项来完成。 $ sdiff -i file1 file2 1A 1a 2 2 3 3 4 4 5 5 6 6 三、忽略空格如果任何文件包含空格，默认情况下sdiff命令将显示差异。但是，如果需要，可以使用-Z命令行选项抑制此行为： $ sdiff file1 file2 1a | 1a 2 2 3 3 4 4 5 5 6 6 $ sdiff -Z file1 file2 1a 1a 2 2 3 3 4 4 5 5 6 6 四、不显示公共行sdiff -s file1 file2]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件比对diff-第二部分]]></title>
    <url>%2F2019%2F11%2F21%2FLinux%E6%96%87%E4%BB%B6%E6%AF%94%E5%AF%B9diff-%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[我们将讨论更多的命令行参数 1、报告文件何时相同默认情况下，文件相同时，不会产生任何输出 $ diff file1 file2 但是，存在命令参数 (-s)可以强制命令行输出此结果 $ diff -s file1 file2 Files file1 and file2 are identical 2、复制的上下文和统一的上下文基本上，这两种格式是diff命令可以产生其输出的两种格式。使用-c命令行选项启用了复制的上下文，而使用-u启用了统一上下文。以下是前者的示例 $ diff -c file1 file2 *** file1 2016-12-29 09:36:47.175597647 +0530 --- file2 2016-12-29 09:19:55.799558326 +0530 *************** *** 1,3 **** Hi ! Helllo Bye --- 1,3 ---- Hi ! Hello Bye 因此，在“复制的上下文”输出格式中，不同的行用感叹号（！）表示。 这是统一上下文格式的示例： $ diff -u file1 file2 --- file1 2016-12-29 09:36:47.175597647 +0530 +++ file2 2016-12-29 09:19:55.799558326 +0530 @@ -1,3 +1,3 @@ Hi -Helllo +Hello Bye 在此输出格式中，在行之前的+和-符号表示不同行的版本：如果file2中缺少file1中的行，则为“-”；当file2中的行添加到file1中时，为“ +”。 3、输出一个”ed”脚本diff命令还能够生成命令，“ ed”编辑器可使用该命令将原始文件（此处为示例中的file1）转换为新文件（file2）。这是您的操作方式： 假设file1和file2包含以下更改： $ diff file1 file2 2c2 &lt; Helllo --- &gt; Hello 现在，使用-e命令行选项生成“ ed”编辑器可以理解的输出，并将该输出重定向到文件中： diff -e file1 file2 &gt; out 输出 2c Hello . 接下来，您需要在out文件的末尾添加命令“ w”。 2c Hello . w 现在，执行命令 ed - file1 &lt; out 您会看到file1和file2现在相同。 $ diff file1 file2 $ 4、在两列中产生输出存在一个命令行选项（-y），用于引导diff在两个单独的列中产生输出。这是一个例子： $ diff -y file1 file2 Hi Hi Helllo | Hello Bye Bye 如您所见，此输出格式使用’|’表示不同的行。 5、隐藏公共行如果您观察到上一节（上面的第4点）中显示的输出，您会注意到，使用-y命令行选项，输出中的diff-也会产生公共行。如果需要隐藏这些相同的行，可以使用–suppress-common-lines选项。 diff -y --suppress-common-lines file1 file2 Helllo | Hello 6、显示C函数的每个变化对于使用diff比较两个C语言文件的情况，有一个命令行选项（-p）指导实用程序精确显示每个更改所在的C函数。例如，假设这是两个C文件： file1.c: #include&lt;stdio.h&gt; void compare(float x, float y) { if(x == y) // incorrect way { printf(&quot;\n EQUAL \n&quot;); } } int main(void) { compare(1.234, 1.56789); return 0; } file2.c: #include&lt;stdio.h&gt; void compare(float x, float y) { if(x == y) { printf(&quot;\n EQUAL \n&quot;); } } int main(void) { compare(1.234, 1.56789); return 0; } 比较输出 $ diff file1.c file2.c 5c5 &lt; if(x == y) // incorrect way --- &gt; if(x == y) 使用-p选项比较文件时： $ diff -p file1.c file2.c *** file1.c 2016-12-29 11:45:36.587010816 +0530 --- file2.c 2016-12-29 11:46:39.823013274 +0530 *************** *** 2,8 **** void compare(float x, float y) { ! if(x == y) // incorrect way { printf(&quot;\n EQUAL \n&quot;); } --- 2,8 ---- void compare(float x, float y) { ! if(x == y) { printf(&quot;\n EQUAL \n&quot;); } 如您所见，使用-p时，diff使您更详细地了解更改的位置，并使用感叹号（！）指示不同的行。 7、递归比较子目录diff命令还允许您递归比较子目录，但这不是默认行为。我的意思是说，如果您采取以下情况： $ diff diff-files/ second-diff-files/ diff diff-files/file1 second-diff-files/file1 1c1 &lt; Hi --- &gt; i diff diff-files/file2 second-diff-files/file2 2c2 &lt; Hello --- &gt; ello diff命令仅比较顶级目录中的文件，但是如果使用命令行选项-r（用于递归diff），则会看到甚至比较了子目录中存在的文件： $ diff -r diff-files/ second-diff-files/ diff -r diff-files/file1 second-diff-files/file1 1c1 &lt; Hi --- &gt; i diff -r diff-files/file2 second-diff-files/file2 2c2 &lt; Hello --- &gt; ello diff -r diff-files/more-diff-files/file1 second-diff-files/more-diff-files/file1 1c1 &lt; Hi --- &gt; i diff -r diff-files/more-diff-files/file2 second-diff-files/more-diff-files/file2 2c2 &lt; Hello --- &gt; ello 8、将缺席文件视为空文件diff命令还提供了一个选项，您可以使用该选项指导该工具将不存在的文件视为空文件。例如，如果将file1与file3（不存在）进行比较，则diff的默认行为是产生错误： $ diff file1 file3 diff: file3: No such file or directory 这本身是没有错的。实际上，这很合理。但是在某些情况下-您可能不想diff命令在这种情况下抛出错误（虽然是bash脚本的一部分，可能是吗？），那么对于这些​​情况，您可以使用-N命令行选项强制命令将不存在的文件视为空文件，然后继续进行比较。 $ diff -N file1 file3 1,5d0 &lt; Hi &lt; &lt; Helllo &lt; &lt; Bye]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件比对diff]]></title>
    <url>%2F2019%2F11%2F21%2FLinux%E6%96%87%E4%BB%B6%E6%AF%94%E5%AF%B9diff%2F</url>
    <content type="text"><![CDATA[Linux Diff 命令 diff [OPTION]... FILES [OPTION]表示多个命令行选项，FILES 通常是2个文件名 Diff 用法 以下为2个我们想要比对的文件 file1： test test2 test3 file2: test test23 test3 比对这2个文件： diff file1 file2 以上命令输出： 2c2 &lt; test2 --- &gt; test23 首先要记住的是，输出表示将file1（通常是原始文件）转换为file2（新文件或更改的文件）所需的更改。输出通常由以数字（或范围）开头，后跟字母（a，d或c）和另一个数字（或范围）的行组成。例如2c2（来自上面的输出）。 第一个数字代表从file1（原始文件）开始的行（或行的范围），而最后一个数字代表从file2（新文件）开始的行（或行的范围）。至于中间的字母，a表示添加，d表示删除，c表示更改。 因此，2c2表示原始文件中的第二行已更改，需要用新文件中的第二行替换才能使文件相同。如果您手动比较两个文件（文件1和文件2），那么您会发现情况确实如此。 至于上述示例中2c2后面的三行，以’&lt;’开头的那一行是file1的第二行，而以’&gt;’开头的那一行是文件2中的那一行。它们之间的三个连字符（—）仅用于分隔目的。 以下是另一个例子 file1 Hi all, This is a diff command tutorial from HowtoForge. Hope you&apos;ll benefit from it. Thanks. file2 Hi all, Welcome to HowtoForge. In this tutorial, we&apos;ll discuss the diff tool. Hope you&apos;ll find it beneficial. Thanks. 比较命令 diff file1 file2 输出： 2,4c2,4 &lt; This is a diff command tutorial &lt; from HowtoForge. &lt; Hope you&apos;ll benefit from it. --- &gt; Welcome to HowtoForge. &gt; In this tutorial, we&apos;ll discuss the diff tool. &gt; Hope you&apos;ll find it beneficial. 输出意味着原始文件（file1）中的行号2到4已更改 接下来，文件1的内容不变，改变文件2的内容如下 Welcome to HowtoForge. In this tutorial, we&apos;ll discuss the diff tool. Hope you&apos;ll find it beneficial. Thanks. Hi all, This is a diff command tutorial from HowtoForge. Hope you&apos;ll benefit from it. Thanks. 当执行比较命令的时候，输出如下 0a1,5 &gt; Welcome to HowtoForge. &gt; In this tutorial, we&apos;ll discuss the diff tool. &gt; Hope you&apos;ll find it beneficial. &gt; Thanks. &gt; 因此，您可以看到该工具立即识别出file2中的第二段是file1包含的内容。因此，输出显示file2的第1至5行应附加在file1的开头，以使两个文件相同。 如果删除文件2的最后一行(“Thanks.”)，将输出 0a1,5 &gt; Welcome to HowtoForge. &gt; In this tutorial, we&apos;ll discuss the diff tool. &gt; Hope you&apos;ll find it beneficial. &gt; Thanks. &gt; 5d9 &lt; Thanks. 您可以看到输出现在还包含5d9，这意味着应该删除file1中的第5行，以便使两个文件从第9行开始同步。当然，这是首先在0a1,5更改之后。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch集群配置]]></title>
    <url>%2F2019%2F11%2F18%2Felasticsearch%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[一 通过编辑配置文件启动集群 config/elasticsearch.ymlmaster配置# 集群名称 cluster.name: chenkl # 节点名称 node.name: master # 存放数据目录,先创建该目录 path.data: /home/elastic/data # 存放日志目录,先创建该目录 path.logs: /home/elastic/logs # 节点IP network.host: 192.168.25.180 # tcp端口 transport.tcp.port: 9300 # http端口 http.port: 9200 # 种子节点列表，主节点的IP地址必须在seed_hosts中 discovery.seed_hosts: [&quot;192.168.25.180&quot;,&quot;192.168.25.181&quot;,&quot;192.168.25.182&quot;] # 主合格节点列表，若有多个主节点，则主节点进行对应的配置 cluster.initial_master_nodes: [&quot;master&quot;] # 主节点相关配置 node.master: true node.data: false node.ingest: false node.ml: false cluster.remote.connect: false # 跨域 http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; slave1cluster.name: chenkl node.name: slave1 path.data: /home/elastic/data path.logs: /home/elastic/logs network.host: 192.168.25.181 transport.tcp.port: 9300 http.port: 9200 discovery.seed_hosts: [&quot;192.168.25.180&quot;,&quot;192.168.25.181&quot;,&quot;192.168.25.182&quot;] cluster.initial_master_nodes: [&quot;master&quot;] node.master: false node.data: true node.ingest: false node.ml: false cluster.remote.connect: false http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; slave2cluster.name: chenkl node.name: slave2 path.data: /home/elastic/data path.logs: /home/elastic/logs network.host: 192.168.25.182 transport.tcp.port: 9300 http.port: 9200 discovery.seed_hosts: [&quot;192.168.25.180&quot;,&quot;192.168.25.181&quot;,&quot;192.168.25.182&quot;] cluster.initial_master_nodes: [&quot;master&quot;] node.master: false node.data: true node.ingest: false node.ml: false cluster.remote.connect: false http.cors.enabled: true http.cors.allow-origin: &quot;*&quot; 启动所有节点cd /home/elasticsearch-7.2.0 ./bin/elasticsearch 问题 max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] #切换到root用户 vi /etc/sysctl.conf #在最后追加 vm.max_map_count=262144 #使用 sysctl -p 查看修改结果 sysctl -p 查看集群是否启动成功查询集群节点curl -XGET &apos;http://localhost:9200/_cat/nodes?v&apos; ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 127.0.0.1 47 96 6 1.26 1.28 0.86 dilm * node-1 127.0.0.1 26 96 6 1.26 1.28 0.86 dilm - node-2 查询单个节点信息curl -XGET &apos;http://localhost:9200/&apos; { &quot;name&quot; : &quot;node-2&quot;, &quot;cluster_name&quot; : &quot;my-es&quot;, &quot;cluster_uuid&quot; : &quot;LnsMM4p1Royo4Ea19viusw&quot;, &quot;version&quot; : { &quot;number&quot; : &quot;7.4.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;2f90bbf7b93631e52bafb59b3b049cb44ec25e96&quot;, &quot;build_date&quot; : &quot;2019-10-28T20:40:44.881551Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.2.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; }, &quot;tagline&quot; : &quot;You Know, for Search&quot; } 二、通过命令行参数启动集群节点cd /home/elasticsearch-7.2.0 节点1 ./bin/elasticsearch -Enode.name=node-1 -Ehttp.port=9200 -Epath.data=/home/elastic/data -Epath.logs=/home/elastic/log 节点2 ./bin/elasticsearch -Enode.name=node-2 -Ehttp.port=8200 -Epath.data=/home/elastic/data1 -Epath.logs=/home/elastic/log1]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch配置]]></title>
    <url>%2F2019%2F11%2F05%2Felasticsearch%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[集群名称,以此作为是否同一集群的判断条件cluster.name: my-application 节点名称，以此作为集群中不同节点的区分条件node.name: node-1 网络地址和HTTP端口network.host: 192.168.0.1 http.port: 9200 外网访问 network.host: 0.0.0.0 数据存储路径path.data: /path/to/data 日志文件路径path.logs: /path/to/logs Development 和 production 模式以network.host是否绑定localhost判断开发模式或是生产模式]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装elasticsearch]]></title>
    <url>%2F2019%2F11%2F05%2F%E5%AE%89%E8%A3%85elasticsearch%2F</url>
    <content type="text"><![CDATA[安装1234567下载curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.4.2-linux-x86_64.tar.gz解压tar -xzvf elasticsearch-7.4.2-linux-x86_64.tar.gzcd elasticsearch-7.4.2启动./bin/elasticsearch 确认是否启动发送HTTP GET请求在9200端口1234567891011121314151617181920curl http://127.0.0.1:9200&#123; &quot;name&quot; : &quot;iZ2ze0fk8pd9zkdd29mpz6Z&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;-Jxq4rGVT_qJLnzJdnj75A&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.4.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;tar&quot;, &quot;build_hash&quot; : &quot;2f90bbf7b93631e52bafb59b3b049cb44ec25e96&quot;, &quot;build_date&quot; : &quot;2019-10-28T20:40:44.881551Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.2.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 报错及解决方法1、内存不足1234567891011121314Exception in thread &quot;main&quot; java.lang.RuntimeException: starting java failed with [1]output:## There is insufficient memory for the Java Runtime Environment to continue.# Native memory allocation (mmap) failed to map 2060255232 bytes for committing reserved memory.# An error report file with more information is saved as:# logs/hs_err_pid29117.logerror:OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x0000000085330000, 2060255232, 0) failed; error=&apos;Not enough space&apos; (errno=12) at org.elasticsearch.tools.launchers.JvmErgonomics.flagsFinal(JvmErgonomics.java:111) at org.elasticsearch.tools.launchers.JvmErgonomics.finalJvmOptions(JvmErgonomics.java:79) at org.elasticsearch.tools.launchers.JvmErgonomics.choose(JvmErgonomics.java:57) at org.elasticsearch.tools.launchers.JvmOptionsParser.main(JvmOptionsParser.java:89) 修改 config目录的jvm.options文件，调小Xms的配置12345678# Xms represents the initial size of total heap space# Xmx represents the maximum size of total heap space#-Xms2g#-Xmx2g-Xms512m-Xmx512m 2、无法使用root用户启动123OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.[2019-11-05T19:57:15,328][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [iZ2ze0fk8pd9zkdd29mpz6Z] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root 添加新用户123456789#添加用户esuseradd es#修改elasticsearch目录使用者/群组chown -R es:es /home/elasticsearch-7.4.2/#切换用户到essu es#启动elasticsearch./bin/elasticsearch]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux sed 命令]]></title>
    <url>%2F2019%2F10%2F22%2FLinux-sed-%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux sed 命令是利用脚本来处理文本文件。 sed 可依照脚本的指令来处理、编辑文本文件。 Sed 主要用来自动编辑一个或多个文件、简化对文件的反复操作、编写转换程序等。 语法1$ sed [-hnV][-e&lt;script&gt;][-f&lt;script文件&gt;][文本文件] 动作说明a ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～c ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！d ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；i ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；p ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～s ：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 1、删除文件里的逗号 $ sed &apos;s/[,]//&apos; 1.txt 2、删除文件特殊字符 1)、首先在vi命令模式下:set list可以将不可看见的特殊字符打印出来2)、这些不可见的特殊字符是可以输入的方式如下比如^I是Tab(\t),^M是WIN的换行(\n\r)请注意^I 不是^ I, ^M也不是^ M^I 是Ctrl + V Ctrl + I^M 是Ctrl + V Ctrl + M3)、然后用sed -i ‘s/^M//g’ a.txt进行删除（这个里边的^M是用2)中的方式输入的,在终端里边是不显示的，如果你要测试的话可以先用sed ‘s/^M//g’ a.txt 看看效果） $ sed -i &apos;s/^M//g&apos; 1.txt 参数-i 使用此参数后，所有改动将在原文件上执行 3、将每行结尾加逗号 sed &apos;s/.*/&amp;,/&apos; 1.txt &amp;号，当它用在替换字符串中的时候，代表的是原始的查找匹配数据 4、删除最后一行逗号 sed &apos;$ s/,//&apos; 1.txt 5、修改原文件的同时生成.bak备份文件 sed -i.bak &apos;s/.*/&amp;,/&apos; 1.txt [参考链接] Linux sed 命令 如何去掉文件中的一些特殊字符]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动脚本安装showdoc]]></title>
    <url>%2F2019%2F10%2F12%2F%E8%87%AA%E5%8A%A8%E8%84%9A%E6%9C%AC%E5%AE%89%E8%A3%85showdoc%2F</url>
    <content type="text"><![CDATA[ShowDoc就是一个非常适合IT团队的在线文档分享工具，它可以加快团队之间沟通的效率。 ShowDoc. 安装自动脚本脚本利用docker来安装运行环境，适用于linux服务器。1234#下载脚本并赋予权限wget https://www.showdoc.cc/script/showdoc;chmod +x showdoc;#默认安装中文版。如果想安装英文版，请加上en参数，如 ./showdoc en./showdoc 其他命令123456789#执行上面命令便会自动安装完成。下面附上脚本其他命令，以便管理showdoc时可以用得上。#停止./showdoc stop #重启./showdoc restart#升级showdoc到最新版./showdoc update#卸载showdoc./showdoc uninstall 使用说明安装好后，showdoc的数据都会存放在 /showdoc_data/html 目录下。./showdoc 脚本可放置在任何目录，方便以后使用。也可以重新从官方地址下载。 你可以打开 http://xxx.com:4999 来访问showdoc (xxx.com为你的服务器域名或者IP)。账户密码是showdoc/123456 从手动方式升级到自动脚本方式 把原来showdoc目录的Sqlite/showdoc.db.php覆盖/showdoc_data/html/Sqlite/showdoc.db.php ，Public/Uploads覆盖 /showdoc_data/html/Public/Uploads 执行命令 12chmod 777 -R /showdoc_data/html ./showdoc update 自动安装shell脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#!/bin/bashif [[ -n "$1" ]] ; then action=$1else action='install'fiif [ "$action" == "start" ] ;then sudo -s service docker start sudo -s docker start showdoc exit 1 fiif [ "$action" == "restart" ] ;then sudo -s docker restart showdoc exit 1fiif [ "$action" == "stop" ] ;then sudo -s docker stop showdoc exit 1fiif [ "$action" == "update" ] ;then DATE=$(date +%Y%m%d_%H%M%S_%N) if [ ! -d "/showdoc_data/html" ]; then echo "/showdoc_data/html 目录不存在" exit 1 ; fi sudo -s docker stop showdoc rm -f master.tar.gz wget https://github.com/star7th/showdoc/archive/master.tar.gz if [ ! -f "master.tar.gz" ]; then docker start showdoc echo "文件下载失败" exit 1 fi sudo -s mv /showdoc_data/html /showdoc_data/html_bak_$&#123;DATE&#125; tar -zxvf master.tar.gz -C /showdoc_data/ sudo -s mv /showdoc_data/showdoc-master /showdoc_data/html ##// */ if [ ! -d "/showdoc_data/html" ]; then echo "/showdoc_data/html 目录不存在" exit 1 ; fi sudo -s chmod 777 -R /showdoc_data/html sudo -s docker start showdoc sleep 10 curl http://localhost:4999/install/non_interactive.php?lang=zh \cp -f /showdoc_data/html_bak_$&#123;DATE&#125;/Sqlite/showdoc.db.php /showdoc_data/html/Sqlite/showdoc.db.php \cp -r -f /showdoc_data/html_bak_$&#123;DATE&#125;/Public/Uploads /showdoc_data/html/Public/Uploads sudo -s curl http://localhost:4999?s=/home/update/db rm -f master.tar.gz exit 1fiif [ "$action" == "uninstall" ] ;then read -r -p "即将卸载showdoc，你是否确认删除showdoc所有数据? [Y/n] " input case $input in [yY][eE][sS]|[yY]) echo "正在卸载..." sudo -s docker stop showdoc sudo -s docker rm showdoc sudo -s docker rmi registry.docker-cn.com/star7th/showdoc sudo -s rm -rf /showdoc_data ;; [nN][oO]|[nN]) ;; *) exit 1 ;; esac exit 1fiif ! [ -x "$(command -v docker)" ]; then echo '检测到Docker尚未安装。正在试图从网络安装...所需时间与你的网络环境有关' sudo -s curl -sSL https://get.daocloud.io/docker | sh sudo -s chkconfig docker on fiif ! [ -x "$(command -v docker)" ]; then echo '检测到Docker尚未安装。正在试图从网络安装...所需时间与你的网络环境有关' sudo -s curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - sudo -s chkconfig docker on fiif ! [ -x "$(command -v docker)" ]; then echo 'Docker自动安装失败,建议你手动安装好docker环境后再启动本脚本' exit 1 fiif [ "$(docker images |grep showdoc)" ]; then echo "你已经安装过showdoc镜像" echo "如果你想更新showdoc，请执行 ./showdoc update " echo "如果你想重启showdoc，请执行 ./showdoc restart " echo "如果你想卸载showdoc，请执行 ./showdoc uninstall " exit 1 fisudo -s service docker startecho '正在拉取showdoc镜像，请稍后...所需时间与你的网络环境有关'sudo -s docker pull registry.docker-cn.com/star7th/showdocsudo -s mkdir /showdoc_dataif [ ! -d "/showdoc_data" ]; then echo "/showdoc_data 目录不存在，请确保有创建权限" exit 1 ;fisudo -s mkdir /showdoc_data/htmlsudo -s chmod 777 -R /showdoc_datasudo -s docker run -d --name showdoc -p 4999:80 -v /showdoc_data/html:/var/www/html/ registry.docker-cn.com/star7th/showdocsleep 10sudo -s docker exec showdoc \cp -fr /showdoc_data/html/ /var/www/sudo -s chmod 777 -R /showdoc_dataif [ "$action" == "en" ] ;then sudo -s curl http://localhost:4999/install/non_interactive.php?lang=enelse sudo -s curl http://localhost:4999/install/non_interactive.php?lang=zhfisudo -s wget http://localhost:4999/install/install.lockif [ -f "install.lock" ]; then rm -rf install.lock echo -e "\n \033[32m 安装成功，访问地址：http://localhost:4999 (你也可以用局域网或者公网IP/域名访问) \033[0m \n" echo -e " \033[32m 账户密码是showdoc/123456，登录后你便可以看到右上方的管理后台入口。建议登录后修改密码。 \033[0m \n" echo -e " \033[32m 对showdoc的问题或建议请至https://github.com/star7th/showdoc 提issue \033[0m \n"fi]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>showdoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo多终端发布博客]]></title>
    <url>%2F2019%2F10%2F12%2Fhexo%E5%A4%9A%E7%BB%88%E7%AB%AF%E5%8F%91%E5%B8%83%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[网站的部署其实就是生成静态文件，hexo下所有生成的静态文件会放在public/文件夹中，所谓部署deploy其实就是将public/文件夹中内容上传到git仓库 换了电脑怎么办？在现有的guthub.io的repository下创建一个分支来管理 克隆仓库到本地 1git clone git@github.com:XXX.github.io.git 删除文件夹里除了.git的其他所有文件 创建一个叫hexo（或者blog，名字随意）的分支，并切换到这个分支 1git checkout -b hexo 把你的blog文件夹内的所有文件全部复制到XXX.github.io/下 添加文件，推送到远程仓库 12345678# 添加所有文件到暂存区git add --all#提交git commit -m ""#推送hexo分支的文件到github仓库git push --set-upstream origin hexo 最后的效果就是仓库中的master放到是生成博客页面的文件（也就是blog/public/下的的文件），分支hexo中存放的就是我们备份的必要的blog中的文件。 发布博客后，执行指令，将备份的文件推送到hexo分支 1234git add . #添加所有文件到暂存区git commit -m "提交一篇博客" #提交git push origin hexo 推送hexo分支到github 今后如果换电脑的话，配置好基本的环境，然后克隆hexo分支到本地,npm install 安装依赖 12git clone -b hexo git@github.com:XXX.github.io.git 综上所述新建博客hexo new post “你好，hexo” ，然后去blog\source_posts 编辑文章。以后每次写完博客，通过hexo g，hexo d发布博客，然后通过git三部曲git add . ; git commit -m “注释” ; git push origin hexo更新备份github的hexo分支即可]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CURL常用命令]]></title>
    <url>%2F2019%2F08%2F07%2FCURL%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[下载单个文件12345# 将文件下载到本地并命名为mygettext.html curl -o mygettext.html http://www.gnu.org/software/gettext/manual/gettext.html # 将文件保存到本地并命名为gettext.html curl -O http://www.gnu.org/software/gettext/manual/gettext.html 断点续传通过使用-C选项可对大文件使用断点续传功能 1234567# 当文件在下载完成之前结束该进程$ curl -O http://www.gnu.org/software/gettext/manual/gettext.html############## 20.1%# 通过添加-C选项继续对该文件进行下载，已经下载过的文件不会被重新下载curl -C - -O http://www.gnu.org/software/gettext/manual/gettext.html############### 21.1% 下载指定时间内修改过的文件当下载一个文件时，可对该文件的最后修改日期进行判断，如果该文件在指定日期内修改过，就进行下载，否则不下载。该功能可通过使用-z选项来实现： 12# 若yy.html文件在2011/12/21之后有过更新才会进行下载 curl -z 21-Dec-11 http://www.example.com/yy.html CURL授权在访问需要授权的页面时，可通过-u选项提供用户名和密码进行授权123curl -u username:password URL # 通常的做法是在命令行只输入用户名，之后会提示输入密码，这样可以保证在查看历史记录时不会将密码泄露curl -u username URL 从FTP服务器下载文件CURL同样支持FTP下载，若在url中指定的是某个文件路径而非具体的某个要下载的文件名，CURL则会列出该目录下的所有文件名而并非下载该目录下的所有文件 12345# 列出public_html下的所有文件夹和文件 curl -u ftpuser:ftppass -O ftp://ftp_server/public_html/ # 下载xss.php文件 curl -u ftpuser:ftppass -O ftp://ftp_server/public_html/xss.php 保存与使用网站cookie信息12345# 将网站的cookies信息保存到sugarcookies文件中 curl -D sugarcookies http://localhost/sugarcrm/index.php # 使用上次保存的cookie信息 curl -b sugarcookies http://localhost/sugarcrm/index.php 传递请求数据默认curl使用GET方式请求数据，这种方式下直接通过URL传递数据可以通过 –data/-d 方式指定使用POST方式传递数据 12345678# GETcurl -u username https://api.github.com/user?access_token=XXXXXXXXXX# POSTcurl -u username --data &quot;param1=value1&amp;param2=value&quot; https://api.github.com# 也可以指定一个文件，将该文件中的内容当作数据传递给服务器端curl --data @filename https://github.api.com/authorizations 注：默认情况下，通过POST方式传递过去的数据中若有特殊字符，首先需要将特殊字符转义在传递给服务器端，如value值中包含有空格，则需要先将空格转换成%20，如： 1curl -d &quot;value%201&quot; http://hostname.com 在新版本的CURL中，提供了新的选项 –data-urlencode，通过该选项提供的参数会自动转义特殊字符。1curl --data-urlencode &quot;value 1&quot; http://hostname.com 除了使用GET和POST协议外，还可以通过 -X 选项指定其它协议，如：1curl -I -X DELETE https://api.github.cim 上传文件1curl --form &quot;fileupload=@filename.txt&quot; http://hostname/resource]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux split文件分割命令]]></title>
    <url>%2F2019%2F07%2F24%2FLinux-split%E6%96%87%E4%BB%B6%E5%88%86%E5%89%B2%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux split命令用于将一个文件分割成数个。 该指令将大文件分割成较小的文件，在默认情况下将按照每1000行切割成一个小文件。1split [--help][--version][-&lt;行数&gt;][-b &lt;字节&gt;][-C &lt;字节&gt;][-l &lt;行数&gt;][要切割的文件][输出文件名] 参数说明： -&lt;行数&gt; : 指定每多少行切成一个小文件 -b&lt;字节&gt; : 指定每多少字节切成一个小文件 –help : 在线帮助 –version : 显示版本信息 -C&lt;字节&gt; : 与参数”-b”相似，但是在切 割时将尽量维持每行的完整性 [输出文件名] : 设置切割后文件的前置文件名， split会自动在前置文件名后再加上编号 指定分割文件行数例如将一个1.txt文件分成前缀为 o_ 的多个小文件，每个文件5000行(-l 5000)后缀为系数形式，系数不是字母而是数字（-d），后缀系数为四位数（-a 4）1split -l 5000 1.txt -d -a 4 o_ 生成文件名如下：‘o_0000’,’o_0001’,’o_0002’,’o_0003’ 指定分割后文件大小split -b 10m 1.log log]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk文本处理示例]]></title>
    <url>%2F2019%2F05%2F09%2Fawk%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[awk命令提供了用于文本处理的脚本语言。使用awk脚本语言，您可以进行以下操作 定义变量 使用字符串和算术运算符 使用控制流和循环 生成格式化报告 实际上，您可以处理包含数百万行的日志文件，以输出可读报告。 awk 选项awk 命令使用方法如下 1$ awk options program file awk 能设置以下参数: -F fs 指定文件分隔符. -f file 指定包含awk脚本的文件. -v var=value 声明一个变量. 读取awk脚本定义一个awk脚本, 使用单引号包围的花括号标记 1$ awk &apos;&#123;print &quot;Welcome to awk command tutorial &quot;&#125;&apos; 使用变量使用awk, 你能处理文本文件. awk 为每一个数据字段赋值了变量： $0 表示整行 $1 表示第一个字段 $2 表示第二个字段 $n 表示第N个字段. 像空格或制表符这样的空白字符是awk中字段之间的默认分隔符 $ awk &apos;{print $1}&apos; myfile D:\&gt;cat myfile This is a test. This is the second test. This is the thrid test. This is the fourth test. D:\&gt;awk &apos;{print $1}&apos; myfile This This This This 上面的例子打印每行的第一个单词 有时某些文件中的分隔符不是空格，也不是制表符，而是其他内容。您可以使用-F选项指定它 1$ awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwd 此命令打印passwd文件中的第一个字段。我们使用冒号作为分隔符，因为passwd文件使用它 使用多个命令要运行多个命令，请使用这样的分号分隔它们 1$ echo &quot;Hello Tom&quot; | awk &apos;&#123;$2=&quot;Adam&quot;; print $0&#125;&apos; 第一个命令使$2字段等于Adam。第二个命令打印整行 从文件中读取脚本您可以在文件中键入awk脚本，并使用-f选项指定该文件。 这里我们从/etc/passwd打印用户名和他的路径，当然分隔符是用大写字母-F指定的 awk脚本testfile如下 { text = $1 &quot; home at &quot; $6 print text } $ awk -F: -f testfile /etc/passwd awk预处理如果您需要为结果创建标题。您可以使用BEGIN关键字来实现此目的。它在处理数据之前运行 $ awk &apos;BEGIN {print &quot;Report Title&quot;}&apos; $ awk &apos;BEGIN {print &quot;The File Contents:&quot;} {print $0}&apos; myfile awk后处理在处理数据后运行脚本，使用END关键字： $ awk &apos;BEGIN {print &quot;The File Contents:&quot;} {print $0} END {print &quot;File footer&quot;}&apos; myfile 这很有用，您可以使用它来添加页脚 让我们将它们组合在一个脚本文件中： BEGIN { print &quot;Users and thier corresponding home&quot; print &quot; UserName \t HomePath&quot; print &quot;___________ \t __________&quot; FS=&quot;:&quot; } { print $1 &quot; \t &quot; $6 } END { print &quot;The end&quot; } 首先，使用BEGIN关键字创建顶部。然后我们定义FS并在末尾打印页脚 $ awk -f myscript /etc/passwd 内置变量变量$1，$2 ,$3用于提取数据字段，我们还处理字段分隔符FS。 但这些不是唯一的变量，还有更多的内置变量。 以下列表显示了一些内置变量： FIELDWIDTHS 指定字段宽度. RS 指定记录分隔符. FS 指定字段分隔符. OFS 指定输出分隔符. ORS 指定输出分隔符. OFS 默认值是空格, 你能指定它 $ awk &apos;BEGIN{FS=&quot;:&quot;; OFS=&quot;-&quot;} {print $1,$6,$7}&apos; /etc/passwd 有时候，字段分布没有指定的分隔符.FIELDWIDTHS 变量能处理这种问题 例如：有以下内容 1235.96521 927-8.3652 36257.8157 $ awk &apos;BEGIN{FIELDWIDTHS=&quot;3 4 3&quot;}{print $1,$2,$3}&apos; testfile D:\&gt;awk &apos;BEGIN{FIELDWIDTHS=&quot;3 4 3&quot;}{print $1,$2,$3}&apos; myfile 123 5.96 521 927 -8.3 652 362 57.8 157 输出字段为每行3个，并且每个字段长度基于 FIELDWIDTH 的设置 更多变量 ARGC 获取传递参数的数量 ARGV 获取命令行参数 ENVIRON shell 环境变量数组 FILENAME awk处理的文件名 NF 每行处理的字段数量 NR 记录总数 FNR 处理的记录 IGNORECASE 忽略字符大小写 $ awk &apos;BEGIN{print ARGC,ARGV[1]}&apos; myfile 2 myfile 获取shell环境变量: $ awk &apos; BEGIN{ print ENVIRON[&quot;PATH&quot;] }&apos; 你可以使用 bash 变量 而不是 ENVIRON 变量: $ echo | awk -v home=$HOME &apos;{print &quot;My home is &quot; home}&apos; NF变量指定记录最后一个字段 $ awk &apos;BEGIN{FS=&quot;:&quot;; OFS=&quot;:&quot;} {print $1,$NF}&apos; /etc/passwd NF 变量能被使用作为一个数据字段: $NF 用户自定义变量你能在shell文件中定义变量如下 $ awk &apos; BEGIN{ test=&quot;Welcome to LikeGeeks website&quot; print test }&apos; 结构化的命令if条件语句 testfile 包含如下内容: 10 15 6 33 45 $ awk &apos;{if ($1 &gt; 30) print $1}&apos; testfile 你能用花括号如果想执行更多语句 $ awk &apos;{ if ($1 &gt; 30) { x = $1 * 3 print x } }&apos; testfile While 循环124 127 130 112 142 135 175 158 245 118 231 147 $ awk &apos;{ sum = 0 i = 1 while (i &lt; 5) { sum += $i i++ } average = sum / 3 print &quot;Average:&quot;,average }&apos; testfile for循环$ awk &apos;{ total = 0 for (var = 1; var &lt; 5; var++) { total += $var } avg = total / 3 print &quot;Average:&quot;,avg }&apos; testfile 格式化输出printf 命令允许你打印指定格式的输出 指定格式如下： %[modifier]control-letter printf可指定的格式有: c 打印数字作为字符串. d 打印整数值. e 打印科学计数值. f 打印浮点数. o 打印八进制值. s 打印文本字符. $ awk &apos;BEGIN{ x = 100 * 100 printf &quot;The result is: %e\n&quot;, x }&apos; 内置方法数学方法sin(x) | cos(x) | sqrt(x) | exp(x) | log(x) | rand() $ awk &apos;BEGIN{x=exp(5); print x}&apos; 字符串方法$ awk &apos;BEGIN{x = &quot;likegeeks&quot;; print toupper(x)}&apos; 用户自定义方法$ awk &apos; function myfunc() { printf &quot;The user %s has home path at %s\n&quot;, $1,$6 } BEGIN{FS=&quot;:&quot;} { myfunc() }&apos; /etc/passwd]]></content>
      <categories>
        <category>awk</category>
      </categories>
      <tags>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬取公众号文章]]></title>
    <url>%2F2018%2F10%2F22%2FPython%E7%88%AC%E5%8F%96%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[chuansong.me收录了很多微信公众号发送的文章，可以从这个网站查找想要爬取的文章。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# -*- coding: utf-8 -*-import requestsfrom requests.exceptions import RequestExceptionimport reimport timeimport jsonimport randomimport osglobal count;count=0;def get_one_page(url): #需要加一个请求头部，不然会被网站封禁 headers = &#123;'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36'&#125; try: response = requests.get(url, headers=headers, timeout=10) response.raise_for_status #若不为200，则引发HTTPError错误 response.encoding = response.apparent_encoding return response.text except: return "产生异常"def mkdir(offset): global count; path = os.getcwd()+'\\'+ str(offset) isExists = os.path.exists(path) path_csv = path +'\\'+ str(offset)+'.csv' if not isExists: os.makedirs(path) with open(path_csv, 'w', encoding='utf-8') as f: f.write('链接,标题,日期' + '\n') #注意，此处的逗号，应为英文格式 f.close() else: count+=1 print("已下载链接数：",count) return path def write_to_file(content, offset): path = mkdir(offset) +'\\'+ str(offset)+'.csv' with open(path, 'a', encoding='utf-8') as f: #追加存储形式，content是字典形式 f.write(str(json.dumps(content, ensure_ascii=False).strip('\'\"') + '\n')) #在写入 f.close() def parse_one_page(html): pattern = re.compile('&lt;div class="feed_item_question"&gt;.*?&lt;span&gt;.*?&lt;a class="question_link" href="(.*?)".*?_blank"&gt;(.*?)&lt;/a&gt;.*?"timestamp".*?"&gt;(.*?)&lt;/span&gt;', re.S) items = re.findall(pattern, html) return items def judge_info(name): url = 'http://chuansong.me/account/' + str(name) + '?start=' + str(0) wait = round(random.uniform(1,2),2) # 设置随机爬虫间隔，避免被封 time.sleep(wait) html = get_one_page(url) pattern1 = re.compile('&lt;h1&gt;Page Not Found.&lt;/h1&gt;', re.S) item1 = re.findall(pattern1, html) # list类型 pattern2 = re.compile('&lt;a href="/account/.*?"&gt;(.\d+)&lt;/a&gt;(\s*)&lt;/span&gt;(\s*?)&lt;a href="/account/.*" style="float: right"&gt;下一页&lt;/a&gt;') item2 = re.findall(pattern2, html) # list类型 if item1: print("\n---------该账号信息尚未收录--------\n") exit(); else: print("\n---------该公众号目前已收录文章页数N为：",item2[0][0]) def main(offset, i): url = 'http://chuansong.me/account/' + str(offset) + '?start=' + str(12*i) print(url) wait = round(random.uniform(1,2),2) # 设置随机爬虫间隔，避免被封 time.sleep(wait) html = get_one_page(url) for item in parse_one_page(html): info = 'http://chuansong.me'+item[0]+','+ item[1]+','+item[2]+'\n' info = repr(info.replace('\n', '')) #print(info) #info.strip('\"') #这种去不掉首尾的“ #info = info[1:-1] #这种去不掉首尾的“ #info.Trim("".ToCharArray()) #info.TrimStart('\"').TrimEnd('\"') write_to_file(info, offset) if __name__ == "__main__": print("\n说明：若程序很快退出，可能是输入的信息有错\n" "\nAuthor:Ctipsy\n") name = input("请输入公众号名称：") judge_info(name); pages = input("\n请输入需要抓取的文章页数(&lt;N):") for i in range(int(pages)): main(name, i) 参考链接 https://blog.csdn.net/gonglun7465/article/details/81945271]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python将HTML转成PDF]]></title>
    <url>%2F2018%2F10%2F21%2F%E4%BD%BF%E7%94%A8Python%E5%B0%86HTML%E8%BD%AC%E6%88%90PDF%2F</url>
    <content type="text"><![CDATA[主要使用的是wkhtmltopdf的Python封装——pdfkit 1、Install python-pdfkit1pip install pdfkit 2、Install wkhtmltopdfLinux在wkhtmltopdf下载对应的文件, 解压文件到环境变量所在目录, 例如 /opt 或者 /usr/local/bin 然后在此执行. Debian / Ubuntu1apt-get install wkhtmltopdf Windows在wkhtmltopdf下载对应安装包，安装完成后将可执行文件目录加入环境变量. 使用12345import pdfkit pdfkit.from_url('http://google.com', 'out.pdf') pdfkit.from_file('test.html', 'out.pdf') pdfkit.from_string('Hello!', 'out.pdf') 传递url或者文件列表12pdfkit.from_url(['google.com', 'yandex.ru', 'engadget.com'], 'out.pdf') pdfkit.from_file(['file1.html', 'file2.html'], 'out.pdf') 传递一个打开的文件12with open('file.html') as f: pdfkit.from_file(f, 'out.pdf') 如果你想对生成的PDF作进一步处理， 你可以将其读取到一个变量中:设置输出文件为False，将结果赋给一个变量1pdf = pdfkit.from_url('http://google.com', False) 参考链接 使用Python将HTML转成PDF python-pdfkit github wkhtmltopdf安装教程 Installing-wkhtmltopdf]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql5.7 datetime 默认值为'0000-00-00 00:00:00'无法创建]]></title>
    <url>%2F2018%2F10%2F15%2Fmysql5-7-datetime-%E9%BB%98%E8%AE%A4%E5%80%BC%E4%B8%BA-0000-00-00-00-00-00-%E6%97%A0%E6%B3%95%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1`create_date` datetime NOT NULL DEFAULT '0000-00-00 00:00:00' mysql5.7设置datetime默认值为 0000-00-00 00:00:00时会报错，[Err] 1067 - Invalid default value for ‘create_date’,这是由于 SQL_MODE 的问题 解决方法1、查看sql_mode：1234select @@sql_mode;//结果ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION NO_ZERO_IN_DATE：在严格模式下，不允许日期和月份为零NO_ZERO_DATE：设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告。 将NO_ZERO_IN_DATE,NO_ZERO_DATE 去掉之后再次新建表就可以了1SET GLOBAL sql_mode='ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION'; 2、改mysql模式修改my.cnf文件，在[mysqld]中添加 1sql-mode=ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 3、把语句改为以下就可以执行创建1create_date DATETIME NOT NULL DEFAULT '0000-01-01 00:00:00']]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP微信公众号素材管理]]></title>
    <url>%2F2018%2F10%2F12%2FPHP%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%B4%A0%E6%9D%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[获取access_token可参考上篇文章 PHP微信公众号开发(一) 本文讲解公众号图文和图片素材的获取获取素材列表接口文档 接口的地址及参数12345678910111213http请求方式: POSThttps://api.weixin.qq.com/cgi-bin/material/batchget_material?access_token=ACCESS_TOKEN&#123; "type":TYPE, "offset":OFFSET, "count":COUNT&#125;参数 是否必须 说明type 是 素材的类型，图片（image）、视频（video）、语音 （voice）、图文（news）offset 是 从全部素材的该偏移位置开始返回，0表示从第一个素材 返回count 是 返回素材的数量，取值在1到20之间 offset为获取列表的偏移量，count为获取数量(最多每页取20条数据)。因此，我们想要获取全部素材的时候可以获取总素材数量，计算出总页数，循环得到每页偏移量进行分页获取。获取素材总数接口文档 接口的地址及参数12345678910http请求方式: GEThttps://api.weixin.qq.com/cgi-bin/material/get_materialcount?access_token=ACCESS_TOKEN//返回说明&#123; "voice_count":COUNT, 语音总数量 "video_count":COUNT, 视频总数量 "image_count":COUNT, 图片总数量 "news_count":COUNT 图文总数量&#125; 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * 获取素材列表 * @param integer $is_get_all [是否获取全部素材] * @param integer $offset [全部素材的偏移位置，0表示从第一个素材] * @param integer $count [返回素材的数量，取值在1到20之间] * @param string $type [素材的类型,图片（image）、视频（video）、语音 （voice）、图文（news）] * @return [type] [description] */ public function actionBatchMaterial($is_get_all = 0,$offset = 0,$count = 20,$type = 'news')&#123; $options = array( 'appid'=&gt;$appid, //公众号AppID 'appsecret'=&gt;$appsecret, //公众号AppSecret ); $this-&gt;wechat = new Wechat($options); //此类文件可从参考链接(微信公众平台php sdk)获取 $list_count = 0; //素材数量 if ($is_get_all) &#123; //获取全部素材 $material_count = $this-&gt;getForeverCount(); //获取素材总数 if ($material_count) &#123; switch ($type) &#123; case 'news': $list_count = $material_count['news_count']; break; case 'image': $list_count = $material_count['image_count']; break; case 'video': $list_count = $material_count['video_count']; break; case 'voice': $list_count = $material_count['voice_count']; break; default: echo "素材类型错误".PHP_EOL; exit(); break; &#125; &#125; &#125; $material_list = []; if ($is_get_all &amp;&amp; $list_count) &#123; $page = ceil($list_count/$count);//计算总页数 for ($i=0; $i &lt; $page; $i++) &#123; //分页获取素材数据 $foreverList = $this-&gt;getForeverList($type,$offset,$count); if ($foreverList) &#123; $material_list[] = $foreverList['item']; &#125; $offset += $count;//计算下页偏移量 &#125; &#125;else&#123; //默认同步最新一页数据 $foreverList = $this-&gt;getForeverList($type,$offset,$count); if ($foreverList) &#123; $material_list[] = $foreverList['item']; &#125; &#125; &#125; /** * [获取图文素材总数] &#123; "voice_count":COUNT, "video_count":COUNT, "image_count":COUNT, "news_count":COUNT &#125; * @return [type] [description] */ private function getForeverCount()&#123; $count = $this-&gt;wechat-&gt;getForeverCount(); if (!empty($this-&gt;wechat-&gt;errMsg) ) &#123; exit($this-&gt;wechat-&gt;errMsg); &#125; return $count; &#125; /** * 获取素材列表 * @param string $type [素材的类型,图片（image）、视频（video）、语音 （voice）、图文（news）] * @param integer $offset [全部素材的偏移位置，0表示从第一个素材] * @param integer $count [返回素材的数量，取值在1到20之间] * @return [type] [description] */ private function getForeverList($type,$offset,$count)&#123; $list = $this-&gt;wechat-&gt;getForeverList($type,$offset,$count); if (!empty($this-&gt;wechat-&gt;errMsg) ) &#123; exit($this-&gt;wechat-&gt;errMsg); &#125; return $list; &#125; [参考链接] 微信公众平台php sdk]]></content>
      <categories>
        <category>公众号</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>公众号</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP微信公众号开发(一)]]></title>
    <url>%2F2018%2F10%2F12%2FPHP%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E5%BC%80%E5%8F%91-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[一、access_token的使用获取access_token微信官方文档 access_token是公众号的全局唯一接口调用凭据，公众号调用各接口时都需使用access_token。开发者需要进行妥善保存。access_token的存储至少要保留512个字符空间。access_token的有效期目前为2个小时，需定时刷新，重复获取将导致上次获取的access_token失效。 1、建议公众号开发者使用中控服务器统一获取和刷新Access_token，其他业务逻辑服务器所使用的access_token均来自于该中控服务器，不应该各自去刷新，否则容易造成冲突，导致access_token覆盖而影响业务；2、公众号需要使用AppID和AppSecret调用本接口来获取access_token。并且需要将调用此接口的服务器IP加到微信后台 “微信公众平台-开发-基本配置”的IP白名单中12345https请求方式: GEThttps://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid=APPID&amp;secret=APPSECRET返回JSON&#123;"access_token":"ACCESS_TOKEN","expires_in":7200&#125;` 获取的access_token可存储于文件、缓存或数据库中，保存其过期时间，当获取的时候判断是否过期，过期则更新access_token的值。yii代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class WeChatAccessToken&#123; //获取微信Access_Token public static function getAccessToken() &#123; //检测本地是否已经拥有access_token，并且检测access_token是否过期 $accessToken = self::_checkAccessToken(); if($accessToken === false)&#123; $accessToken = self::_getAccessToken(); &#125; return isset($accessToken['access_token'])?$accessToken['access_token']:''; &#125; //从微信服务器获取微信ACCESS_TOKEN private static function _getAccessToken() &#123; $appid = \Yii::$app-&gt;params['wechat']['appid']; $appsecret = \Yii::$app-&gt;params['wechat']['appsecret']; $url = 'https://api.weixin.qq.com/cgi-bin/token?grant_type=client_credential&amp;appid='.$appid.'&amp;secret='.$appsecret; $accessToken = Helper::curlGet($url); $accessTokenArr = json_decode($accessToken,true); if(!isset($accessTokenArr['access_token']))&#123; return ''; &#125; $accessTokenArr['time'] = time(); //缓冲 token Yii::$app-&gt;redis_cache-&gt;set('weixin_access_token',json_encode($accessTokenArr),7260); return $accessTokenArr; &#125; //检测微信ACCESS_TOKEN是否过期 private static function _checkAccessToken() &#123; $data = Yii::$app-&gt;redis_cache-&gt;get('weixin_access_token'); $accessToken['value'] = $data; if(!empty($accessToken['value']))&#123; $accessToken = json_decode($accessToken['value'], true); if(time() - $accessToken['time'] &lt; $accessToken['expires_in']-10)&#123; return $accessToken; &#125; &#125; return false; &#125;&#125;class Helper&#123; //GET 请求 public static function curlGet($url)&#123; $oCurl = curl_init(); if(stripos($url,"https://")!==FALSE)&#123; curl_setopt($oCurl, CURLOPT_SSL_VERIFYPEER, FALSE); curl_setopt($oCurl, CURLOPT_SSL_VERIFYHOST, FALSE); curl_setopt($oCurl, CURLOPT_SSLVERSION, 1); //CURL_SSLVERSION_TLSv1 &#125; curl_setopt($oCurl, CURLOPT_URL, $url); curl_setopt($oCurl, CURLOPT_RETURNTRANSFER, 1 ); $sContent = curl_exec($oCurl); $aStatus = curl_getinfo($oCurl); curl_close($oCurl); if(intval($aStatus["http_code"])==200)&#123; return $sContent; &#125;else&#123; return false; &#125; &#125;&#125;]]></content>
      <categories>
        <category>公众号</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>公众号</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker常用命令]]></title>
    <url>%2F2018%2F09%2F14%2FDocker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[运行一个应用123docker pull nginxdocker run -d -p 8080:80 --name='nginx1' -v /local/html:/usr/share/nginx/html nginx -d:让容器在后台运行。-p:将容器80端口映射到宿主机8080端口。 查看正在运行的容器1docker ps 使用 docker port 可以查看指定 （ID或者名字）容器的某个确定端口映射到宿主机的端口号1docker port 7a38a1ad55c6 查看WEB应用程序日志1docker logs -f 7a38a1ad55c6 检查WEB应用程序,使用 docker inspect 来查看Docker的底层信息。它会返回一个 JSON 文件记录着 Docker 容器的配置和状态信息。1docker inspect determined_swanson 停止、启动、删除容器123docker stop determined_swanson docker start determined_swansondocker rm determined_swanson docker exec ：在运行的容器中执行命令-d :分离模式: 在后台运行 -i :即使没有附加也保持STDIN 打开 -t :分配一个伪终端 在容器mynginx中以交互模式执行容器内/root/runoob.sh脚本1docker exec -it mynginx /bin/sh /root/runoob.sh 在容器mynginx中以交互模式执行容器内/root/runoob.sh脚本1docker exec -i -t mynginx /bin/bash]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 安装]]></title>
    <url>%2F2018%2F09%2F10%2FDocker-%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[一、win7、win8 系统win7、win8 等需要利用 docker toolbox 来安装，国内可以使用阿里云的镜像来下载，下载地址：http://mirrors.aliyun.com/docker-toolbox/windows/docker-toolbox/ 下载安装完成后，点击 Docker QuickStart 图标来启动 Docker Toolbox 终端。 1docker run hello-world 二、 CentOS 6.8 安装 DockerCentOS 7 的内核一般都是3.10的，而CentOS 6.X 的内核一般都是2.6，在2.6的内核下，Docker运行会比较卡，所以一般会选择升级到3.10版本。 安装docker-io1[root@localhost ~]# yum install docker-io 三、使用 yum 安装（CentOS 7下） Docker 要求 CentOS 系统的内核版本高于 3.10 。 通过 uname -r 命令查看你当前的内核版本 1[root@runoob ~]# uname -r 3.10.0-327.el7.x86_64 参考链接： 使用 yum 安装（CentOS 7下） 配置 Docker 加速器参考链接： Docker 加速器） [参考链接] Docker 教程 CentOS 6.8 安装 Docker]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pyenv切换python版本]]></title>
    <url>%2F2018%2F07%2F26%2Fpyenv%E5%88%87%E6%8D%A2python%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[1、查看版本1pyenv install --list 指定版本安装1pyenv install 3.4.3 -v 2.安装后，记得要更新1pyenv rehash 3.查看已安装版本1pyenv versions system (set by /home/seisman/.pyenv/version)3.4.3 4.指定版本1pyenv global 3.4.3 5.切回原来版本1pyenv global system]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地配置多个ssh key]]></title>
    <url>%2F2018%2F07%2F23%2F%E6%9C%AC%E5%9C%B0%E9%85%8D%E7%BD%AE%E5%A4%9A%E4%B8%AAssh-key%2F</url>
    <content type="text"><![CDATA[1、为gitlab生成ssh key1ssh-keygen -t rsa -C 'yourEmail@xx.com' -f ~/.ssh/gitlab-rsa 2、为github生成ssh key1ssh-keygen -t rsa -C 'yourEmail2@xx.com' -f ~/.ssh/github-rsa 3、在~/.ssh目录下新建名称为config的文件（无后缀名）。用于配置多个不同的host使用不同的ssh key，内容如下： 12345678910111213141516# gitlabHost gitlab.com HostName gitlab.com PreferredAuthentications publickey IdentityFile ~/.ssh/gitlab-rsa# githubHost github.com HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/github-rsa ​# 配置文件参数# Host : Host可以看作是一个你要识别的模式，对识别的模式，进行配置对应的的主机名和ssh文件# HostName : 要登录主机的主机名# User : 登录名# IdentityFile : 指明上面User对应的identityFile路径 4、按照上面的步骤分别往gitlab和github上添加生成的公钥gitlab-rsa.pub和github-rsa.pub 5、查看ssh keycat ~/.ssh/github-rsa.pub 6、测试是否连接ssh -T git@github.com]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python导出CSV]]></title>
    <url>%2F2018%2F07%2F17%2FPython%E5%AF%BC%E5%87%BACSV%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132#!/usr/bin/env python# -*- coding: utf-8 -*-import pymysqlimport ioimport sysimport csvimport timesys.stdout = io.TextIOWrapper(sys.stdout.buffer,encoding='gb18030') #改变标准输出的默认编码 sql ="SELECT hospital_id, type FROM `tb_hospital`"start = time.time()db = pymysql.connect(host='127.0.0.1',user='root', password='123456', port=3306, db='db_kr',charset='utf8')cursor = db.cursor()cursor.execute(sql)results = cursor.fetchall()print('Count:', cursor.rowcount)i=0with open('hospital_type.csv', 'a+', encoding='utf-8',newline='') as csvfile: writer = csv.writer(csvfile) writer.writerow([ 'hospital_id', '类型']) for row in results: i = i + 1 print("第",i) writer.writerow(row)end = time.time()print('Cost time:',end-start)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[awk文件比对]]></title>
    <url>%2F2018%2F06%2F25%2Fawk%E6%96%87%E4%BB%B6%E6%AF%94%E5%AF%B9%2F</url>
    <content type="text"><![CDATA[文件以制表符\t分隔1、将某几列作为主键key，对某列求和1awk '&#123;sum[$1,$2]+=$3&#125;END&#123;for(c in sum)&#123;print c,sum[c] &#125;&#125;' 1.txt &gt; 3.txt 2、两个文件比较 while((getline &lt; “1.txt”)&gt;0 //读到文件末尾1cat 2|awk -F"\t" 'BEGIN&#123;while((getline &lt; "1")&gt;0) hash[$1$2]=$3&#125;&#123;if(hash[$1$2]-$3&gt;1 || hash[$1$2]-$3&lt;-1) print $0"|"hash[$1$2]&#125;' 3、提取某列输出重复数据项1cat 1 |awk '&#123;print $1&#125;' |sort|uniq -c|awk '&#123;if($1==2) print $0&#125;' 4、在文件1不在文件2的数据项1cat 1 2 1|sort |uniq -c|awk '&#123;if($1==2) print $0&#125;' 5、找出2个文件差异项1cat 1.txt 2.txt |sort |uniq -u]]></content>
      <categories>
        <category>awk</category>
      </categories>
      <tags>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL备份]]></title>
    <url>%2F2018%2F04%2F09%2FMYSQL%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[mysql mysqldump 只导出表结构 不导出数据1mysqldump --opt -d 数据库名 -u root -p &gt; xxx.sql 备份数据库12#mysqldump 数据库名 &gt;数据库备份名 #mysqldump -A -u用户名 -p密码 数据库名&gt;数据库备份名 #mysqldump -d -A --add-drop-table -uroot -p &gt;xxx.sql 1.导出结构不导出数据1mysqldump --opt -d 数据库名 -u root -p &gt; xxx.sql 2.导出数据不导出结构1mysqldump -t 数据库名 -uroot -p &gt; xxx.sql 3.导出数据和表结构1mysqldump 数据库名 -uroot -p &gt; xxx.sql 4.导出特定表的结构1mysqldump -uroot -p -B 数据库名 --table 表名 &gt; xxx.sql 导入数据：12#mysql 数据库名 &lt; 文件名 #source /tmp/xxx.sql]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MYSQL 导入导出CSV]]></title>
    <url>%2F2018%2F04%2F09%2FMysql-%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BACSV%2F</url>
    <content type="text"><![CDATA[MYSQL命令行导出 csv文件12345678mysql &gt; SELECT *FROM table_name INTO OUTFILE 'D:/test.csv' FIELDS TERMINATED BY ',' -----字段间以,号分隔 OPTIONALLY ENCLOSED BY '"' ------字段用"号括起 escaped by '"' ------字段中使用的转义符为" LINES TERMINATED BY '\n'; ------行以\n结束 MYSQL命令行导入 csv文件基本语法123456789load data [low_priority] [local] infile 'file_name txt' [replace | ignore]into table tbl_name[fields[terminated by't'][OPTIONALLY] enclosed by ''][escaped by'\' ]][lines terminated by'n'][ignore number lines][(col_name, )] 示例1234567891011LOAD DATA LOCAL INFILE 'D:/test.csv' REPLACE INTO TABLE table_name FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '' ESCAPED BY '\"' LINES TERMINATED BY '\n' ( field1, field2, create_date, update_date); load data infile语句从一个文本文件中以很高的速度读入一个表中。使用这个命令之前，mysqld进程（服务）必须已经在运行。为了安全原因，当读取位于服务器上的文本文件时，文件必须处于数据库目录或可被所有人读取。另外，为了对服务器上文件使用load data infile，在服务器主机上你必须有file的权限。 1 如果你指定关键词low_priority，那么MySQL将会等到没有其他人读这个表的时候，才把插入数据。可以使用如下的命令：load data low_priority infile “/home/mark/data sql” into table Orders; 2 如果指定local关键词，则表明从客户主机读文件。如果local没指定，文件必须位于服务器上。3 replace和ignore关键词控制对现有的唯一键记录的重复的处理。如果你指定replace，新行将代替有相同的唯一键值的现有行。如果你指定ignore，跳过有唯一键的现有行的重复行的输入。如果你不指定任何一个选项，当找到重复键时，出现一个错误，并且文本文件的余下部分被忽略。例如：load data low_priority infile “/home/mark/data sql” replace into table Orders; 4 分隔符（1） fields关键字指定了文件字段的分割格式，如果用到这个关键字，MySQL剖析器希望看到至少有下面的一个选项：terminated by分隔符：意思是以什么字符作为分隔符enclosed by字段括起字符escaped by转义字符terminated by描述字段的分隔符，默认情况下是tab字符（\t）enclosed by描述的是字段的括起字符。escaped by描述的转义字符。默认的是反斜杠（backslash：\ ）例如：load data infile “/home/mark/Orders txt” replace into table Orders fields terminated by’,’ enclosed by ‘“‘; （2）lines 关键字指定了每条记录的分隔符默认为’\n’即为换行符如果两个字段都指定了那fields必须在lines之前。如果不指定fields关键字缺省值与如果你这样写的相同： fields terminated by’\t’ enclosed by ’ ‘’ ‘ escaped by’\‘如果你不指定一个lines子句，缺省值与如果你这样写的相同： lines terminated by’\n’例如：load data infile “/jiaoben/load.txt” replace into table test fields terminated by ‘,’ lines terminated by ‘/n’; 5 load data infile 可以按指定的列把文件导入到数据库中。 当我们要把数据的一部分内容导入的时候，，需要加入一些栏目（列/字段/field）到MySQL数据库中，以适应一些额外的需要。比方说，我们要从Access数据库升级到MySQL数据库的时候下面的例子显示了如何向指定的栏目(field)中导入数据：load data infile “/home/Order txt” into table Orders(Order_Number, Order_Date, Customer_ID); 6 当在服务器主机上寻找文件时，服务器使用下列规则：（1）如果给出一个绝对路径名，服务器使用该路径名。（2）如果给出一个有一个或多个前置部件的相对路径名，服务器相对服务器的数据目录搜索文件。（3）如果给出一个没有前置部件的一个文件名，服务器在当前数据库的数据库目录寻找文件。例如： /myfile txt”给出的文件是从服务器的数据目录读取，而作为“myfile txt”给出的一个文件是从当前数据库的数据库目录下读取。 [参考链接] mysql导入数据load data infile用法(将txt文件中的数据导入表中)]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python安装]]></title>
    <url>%2F2017%2F10%2F12%2FPython%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装Python 3.X在Windows上安装Python根据你的Windows版本（64位还是32位）从Python的官方网站www.python.org下载，然后，运行下载的EXE安装包 在Linux上安装Python打开WEB浏览器访问www.python.org/download选择适用于Unix/Linux的源码压缩包。这里，我选择的版本是 3.5.2 123456789101112下载#wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz解压压缩包#tar -zxvf Python-3.5.2.tgz进入目录#cd Python-3.5.2/添加配置#./configure编译程序#make执行安装#make install 执行以上操作后，Python会安装在 /usr/local/bin 目录中，Python库安装在/usr/local/lib/pythonXX，XX为你使用的Python的版本号。 验证 安装成功以后，就可以查看 Python 的版本了：1234# python -VPython 2.7.5# python3 -VPython 3.5.2 设置 3.x 为默认版本查看 Python 的路径，在 /usr/bin 下面。可以看到 python 链接的是 python 2.7，所以，执行 python 就相当于执行 python 2.7。12345678910111213141516# ls -al /usr/bin | grep python-rwxr-xr-x. 1 root root 11216 12月 1 2015 abrt-action-analyze-pythonlrwxrwxrwx. 1 root root 7 8月 30 12:11 python -&gt; python2lrwxrwxrwx. 1 root root 9 8月 30 12:11 python2 -&gt; python2.7-rwxr-xr-x. 1 root root 7136 11月 20 2015 python2.7将原来 python 的软链接重命名：# mv /usr/bin/python /usr/bin/python.bak将 python 链接至 python3：# ln -s /usr/local/bin/python3 /usr/bin/python这时，再查看 Python 的版本：# python -VPython 3.5.2输出的是 3.x，说明已经使用的是 python3了。 [参考链接] Python 环境搭建 Linux 升级 Python 至 3.x]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux在history添加时间和用户]]></title>
    <url>%2F2017%2F09%2F30%2FLinux%E5%9C%A8history%E6%B7%BB%E5%8A%A0%E6%97%B6%E9%97%B4%E5%92%8C%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[设置显示时间和用户1echo 'export HISTTIMEFORMAT="[%Y.%m.%d %H:%M:%S] [`whoami`] "' &gt;&gt; /etc/profile 执行source使配置生效12source /etc/profile]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python独立开发环境virtualenv配置]]></title>
    <url>%2F2017%2F07%2F03%2FPython%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[什么是virtualenv Virtualenv是一个用来创建独立的Python环境的包。 你可以为每个项目建立不同的/独立的Python环境，你将为每个项目安装所有需要的软件包到它们各自独立的环境中。 安装与使用virtualenv1pip install virtualenv virtualenv安装完毕后，可以通过运行下面的命令在项目目录myproject创建独立的python环境123mkdir myprojectcd myprojectvirtualenv --no-site-packages myproject 参数–no-site-packages代表已经安装到系统Python环境中的所有第三方包都不会复制过来，这样，我们就得到了一个不带任何第三方包的“干净”的Python运行环境。 以上代码安装的是系统默认的python版本，如果需要安装指定版本的python，比如安装python2.7可以用以下代码。123mkdir myprojectcd myprojectvirtualenv --no-site-packages --python=C:\Python27\python.exe myproject 通过下面的命令激活这个virtualenv：activate为激活文件1source bin/activate windows执行12cd Scriptsactivate 1(myproject) D:\houyimin\learnpython\myproject\Scripts&gt; 注意到命令提示符变了，有个(myproject)前缀，表示当前环境是一个名为myproject的Python环境。 运行下面的命令退出virtualenv环境。1deactivate virtualenv拷贝了Python可执行文件的副本，并创建一些有用的脚本和安装了项目需要的软件包，你可以在项目的整个生命周期中安装/升级/删除这些包。 它也修改了一些搜索路径，例如PYTHONPATH，以确保：当安装包时，它们被安装在当前活动的virtualenv里，而不是系统范围内的Python路径。当import代码时，virtualenv将优先采取本环境中安装的包，而不是系统Python目录中安装的包。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP导出大数据到Excel]]></title>
    <url>%2F2017%2F06%2F29%2FPHP%E5%AF%BC%E5%87%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%B0Excel%2F</url>
    <content type="text"><![CDATA[数据量很大时（5万条以上），用 PHPExcel 导出 xls 将十分缓慢且占用很大内存，最终造成运行超时或内存不足。可以通过设置 PHP 的运行时间和内存限制来阻止错误发生，但仍然不能确保导出完成。 12set_time_limit(0);ini_set("memory_limit","512M"); 一、 可生成多个链接分页进行导出要彻底解决这个问题可以将数据分批导出成 CSV 格式的文件，这种格式简单导出快，并且也能用到 Excel 中。 我们用php提供的fputcsv来导出一百万的数据，原理就是打开一个标准输出流，然后把数据按一万条来分割，每一万条就刷新缓冲区。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?phpset_time_limit(0);ini_set('memory_limit', '128M'); $fileName = date('YmdHis', time());header('Content-Type: application/vnd.ms-execl');header('Content-Disposition: attachment;filename="' . $fileName . '.csv"'); $begin = microtime(true); //打开php标准输出流//以写入追加的方式打开$fp = fopen('php://output', 'a'); $db = new mysqli('127.0.0.1', 'root', '', 'test'); if($db-&gt;connect_error) &#123; die('connect error');&#125; //我们试着用fputcsv从数据库中导出1百万的数据//我们每次取1万条数据，分100步来执行//如果线上环境无法支持一次性读取1万条数据，可把$nums调小，$step相应增大。$step = 100;$nums = 10000; //设置标题$title = array('ID', '用户名', '用户年龄', '用户描述', '用户手机', '用户QQ', '用户邮箱', '用户地址');foreach($title as $key =&gt; $item) &#123; $title[$key] = iconv('UTF-8', 'GBK', $item);&#125;//将标题写到标准输出中fputcsv($fp, $title); for($s = 1; $s &lt;= $step; ++$s) &#123; $start = ($s - 1) * $nums; $result = $db-&gt;query("SELECT * FROM tb_users ORDER BY id LIMIT &#123;$start&#125;,&#123;$nums&#125;"); if($result) &#123; while($row = $result-&gt;fetch_assoc()) &#123; foreach($row as $key =&gt; $item) &#123; //这里必须转码，不然会乱码 $row[$key] = iconv('UTF-8', 'GBK', $item); &#125; fputcsv($fp, $row); &#125; $result-&gt;free(); //每1万条数据就刷新缓冲区 ob_flush(); flush(); &#125;&#125; $end = microtime(true);echo '用时：', $end - $begin; 生成一个文件数据过大，可以生成下载链接进行单个导出。1234567891011121314151617181920212223242526//表单&lt;form action="&lt;?php echo $this-&gt;createUrl('/offlinead/default/index');?&gt;" id="myform" method="get" &gt; &lt;button type="button" class="btn btn-info" id="exportBtn"&gt;导出Excel&lt;/button&gt; &lt;/form&gt; // 导出excel js $("#exportBtn").click(function () &#123; var params = $("#myform").serialize(); var url = "&lt;?php echo $this-&gt;createUrl('/offlinead/default/index'); ?&gt;"; //获取查询数据的条数 $.get(url+"?is_get_num=1&amp;export=1&amp;" + params, function(data) &#123; var downDataList = ""; if(data["rows"]) &#123; //rows是数据总条数，pageSize是一页多少条 var pageNum = Math.ceil(data["rows"] / data["pageSize"]); for(var i = 1; i &lt;= pageNum; ++i) &#123; downDataList += "&lt;a href='"+url+"?export=1&amp;" + params + "&amp;page=" + i + "'&gt;下载汇总结果" + i + "&lt;/a&gt;&amp;nbsp;&amp;nbsp;"; &#125; $("#searchDataList").html(downDataList); &#125; else &#123; commonjs.alert("没有数据"); &#125; &#125;, "json"); return false; &#125;); 二、 生成多个文件到一个目录，打包导出JS代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546 var pageNum = 0; //总页数 // 导出excel $("#exportBtn").click(function () &#123; var params = $("#myform").serialize(); var url = "&lt;?php echo $this-&gt;createUrl('/offlinead/default/index'); ?&gt;"; //获取查询数据的条数 $.get(url+"?is_get_num=1&amp;export=1&amp;" + params, function(data) &#123; if(data["rows"]) &#123; //rows是数据总条数，pageSize是一页多少条 pageNum = Math.ceil(data["rows"] / data["pageSize"]); excel(1); //生成excel文件 console.log("正在生成第一页\n"); &#125; else &#123; commonjs.alert("没有数据"); &#125; &#125;, "json"); return false; &#125;);//生成csv文件 function excel(page) &#123; //向后台发送处理数据 $.ajax(&#123; type: "POST", dataType: "text", url: '&lt;?php echo Yii::app()-&gt;createUrl("/offlinead/default/index"); ?&gt;?' + $("#myform").serialize() + '&amp;export=1&amp;page='+page, //分页生成excel地址 data: "", error: function () &#123; commonjs.alert("下载失败"); &#125;, success: function (data) &#123; if (data == 1) &#123; var nowpage = page+1; if (nowpage &lt;= pageNum+1) &#123; excel(nowpage); // console.log("正在生成第"+nowpage+"页\n"); &#125; &#125; else if(data == 0) &#123; commonjs.alert("下载失败"); &#125;else&#123; location.href = data; //跳转到生成的zip包进行下载 &#125; &#125; &#125;); &#125; PHP代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758$list = $this-&gt;getOrder($this-&gt;page,$this-&gt;pageSize);//当前页查询到的数据if ($this-&gt;page &lt;= $pagenum) &#123; //当前页小于总页数，生成csv $date = date("Ymd"); $p =$this-&gt;page;//当前页数 $filename = $this-&gt;_upload_path.$date."-".$p.'.csv';//$this-&gt;_upload_path生成文件路径 $this-&gt;exportCSVCommand($filename,$list);//生成csv echo 1; //生成单页数据成功 &#125;else&#123; //全部生成完以后，对生成目录进行打包 $zip=new ZipArchive();//php打包类,xxx.zip为压缩包文件名 if($zip-&gt;open($this-&gt;_upload_path.'xxx.zip', ZipArchive::OVERWRITE)=== TRUE)&#123; $this-&gt;addFileToZip($this-&gt;_upload_path, $zip); //调用方法，对要打包的根目录进行操作，并将ZipArchive的对象传递给方法 $zip-&gt;close(); //关闭处理的zip文件 echo $this-&gt;_upload_path.'xxx.zip';//返回前端压缩包目录，进行下载 &#125;else&#123; echo 0; //打包失败 &#125; &#125;//根据数组生成excel文件 public function exportArrayCommand($fileName, $array) &#123; $fp = fopen($fileName, 'w'); // 计数器 $cnt = 0; // 每隔$limit行，刷新一下输出buffer $limit = 10000; // 逐行取出数据，不浪费内存 foreach ($array as $row) &#123; $cnt ++; if ($limit == $cnt) &#123; //刷新一下输出buffer，防止由于数据过多造成问题 ob_flush(); flush(); $cnt = 0; &#125; foreach ($row as $i =&gt; $v) &#123; $row[$i] = iconv('utf-8', 'gb2312', $v); &#125; fputcsv($fp, $row); &#125; fclose($fp); &#125;//将指定目录文件，加入到压缩文件对象 public function addFileToZip($path,$zip)&#123; $handler=opendir($path); //打开当前文件夹由$path指定。 while(($filename=readdir($handler))!==false)&#123; if($filename != "." &amp;&amp; $filename != "..")&#123;//文件夹文件名字为'.'和‘..’，不要对他们进行操作 if(is_dir($path.DIRECTORY_SEPARATOR.$filename))&#123;// 如果读取的某个对象是文件夹，则递归 addFileToZip($path."/".$filename, $zip); &#125;else&#123; //将文件加入zip对象 $zip-&gt;addFile($path."/".$filename); &#125; &#125; &#125; @closedir($path); &#125;]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设置cmd命令提示符窗口的界面语言]]></title>
    <url>%2F2017%2F06%2F29%2F%E8%AE%BE%E7%BD%AEcmd%E5%91%BD%E4%BB%A4%E6%8F%90%E7%A4%BA%E7%AC%A6%E7%AA%97%E5%8F%A3%E7%9A%84%E7%95%8C%E9%9D%A2%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[chcp 是 “change code page”的缩写，chcp命令查看当前代码页 “chcp 437” 命令的作用是更改代码页。 437 是美国英语的代码页936 是中文的代码页，936就是cmd默认的代码页]]></content>
  </entry>
  <entry>
    <title><![CDATA[PHPStorm 设置调试工具XDebug]]></title>
    <url>%2F2017%2F06%2F07%2FPHPStorm-%E8%AE%BE%E7%BD%AE%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7XDebug%2F</url>
    <content type="text"><![CDATA[安装XDebug如果使用的PHP开发环境是phpStudy，本身已经安装了XDebug扩展，只需在php.ini中开启即可。12345[XDebug]xdebug.profiler_output_dir="D:\phpStudy\tmp\xdebug"xdebug.trace_output_dir="D:\phpStudy\tmp\xdebug"zend_extension="D:\phpStudy\php\php-5.5.38\ext\php_xdebug.dll"xdebug.remote_enable = on 如果没有安装，可以到 xdebug网站 下载相应版本的XDebug扩展php_xdebug.dll,只需将phpinfo的内容复制到输入框，第一种方式可以打印phpinfo()，复制网页内容，第二种方式在命令行将phpinfo的内容输出到文件中 php -i &gt;phpinfo.txt ，复制phpinfo.txt的内容到输入框。最后点击按钮 Analyse my phpinfo() output 就会显示你要下载的版本。 设置PHPStorm一、 添加服务器信息1、 进入File&gt;Settings&gt;Languages &amp; Frameworks&gt;PHP&gt;Servers，根据自己的域名进行设置，www.xywang.net是我配置的要进行debug的域名。 2、进入File&gt;Settings&gt;Languages &amp; Frameworks&gt;PHP&gt;Debug&gt;DBGp Proxy 填写：123IDE key: phpStorm host: www.xywang.net port: 80 3、最后点菜单栏的Run&gt;Edit Configurations… 在弹出的窗口中添加一个调试配置：点击左上角加号，选择PHP Web Application，选择刚才配置的Server，选择默认浏览器为chrome 二、安装chrome调试插件Xdebug helper安装好后在浏览器右上角会有一个灰色的小甲虫，右键选项中设置IDE key为PhpStorm,调试时要选择Debug选项成为绿色。 开始调试调试时，在phpstrom中设置好断点，并点击右上角开始监听调试按钮，最后刷新网页即可进行调试。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3.5安装加密模块pycrypto]]></title>
    <url>%2F2017%2F06%2F01%2Fpython3-5%E5%AE%89%E8%A3%85%E5%8A%A0%E5%AF%86%E6%A8%A1%E5%9D%97pycrypto%2F</url>
    <content type="text"><![CDATA[安装代码如下1pip install --use-wheel --no-index --find-links=https://github.com/sfbahr/PyCrypto-Wheels/raw/master/pycrypto-2.6.1-cp35-none-win_amd64.whl pycrypto]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo的NexT主题：添加来必力评论]]></title>
    <url>%2F2017%2F05%2F26%2FHexo%E7%9A%84NexT%E4%B8%BB%E9%A2%98%EF%BC%9A%E6%B7%BB%E5%8A%A0%E6%9D%A5%E5%BF%85%E5%8A%9B%E8%AF%84%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[来必力是什么？ 使用社交网站账户登录，免去注册过程。 提高用户的参与和沟通意愿。 管理/删除我的评论内容。 提供管理页面，管理网站文章及评论内容。 安装来必力1 、登陆来必力网站注册2 、在后台的代码管理页面 查看一般网站的安装代码,复制data-uid的值 3、打开next主题的配置文件 \themes\next_config.yml，找到 livere_uid 设置为该值即可。123# Support for LiveRe comments system.# You can get your uid from https://livere.com/insight/myCode (General web site)livere_uid: 这里填写data-uid的值 基本设置1 、注意需要在来必力后台管理的设置中添加网站名称和网站的URL，可根据情况选择要显示的SNS第三方登陆按钮。 2、评论提醒：在评论提醒开启登记新评论时，接受提醒，填写接受提醒的邮箱地址以及选择提醒周期。3、评论管理中可针对接收到的评论进行管理。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo的NexT主题：显示网站访问人数和总访问量]]></title>
    <url>%2F2017%2F05%2F18%2FHexo%E7%9A%84NexT%E4%B8%BB%E9%A2%98%EF%BC%9A%E6%98%BE%E7%A4%BA%E7%BD%91%E7%AB%99%E8%AE%BF%E9%97%AE%E4%BA%BA%E6%95%B0%E5%92%8C%E6%80%BB%E8%AE%BF%E9%97%AE%E9%87%8F%2F</url>
    <content type="text"><![CDATA[显示统计标签打开\themes\next\layout_partials\footer.swig文件，复制以下代码至你想要放置的位置。12345678910111213141516&lt;div class="busuanzi-count"&gt; &lt;script async="" src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt; &lt;span class="site-uv"&gt; &lt;i class="fa fa-user"&gt; 本站访客数&lt;/i&gt; &lt;span class="busuanzi-value" id="busuanzi_value_site_uv"&gt;&lt;/span&gt; 人 &lt;/span&gt; &lt;span class="site-pv"&gt; &lt;i class="fa fa-eye"&gt; 本站总访问量&lt;/i&gt; &lt;span class="busuanzi-value" id="busuanzi_value_site_pv"&gt;&lt;/span&gt; 次 &lt;/span&gt;&lt;/div&gt;]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F04%2F12%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
